<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 02: Measures of Central Tendency - Normal Distribution & Paired Datasets</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            }
        };
    </script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f8f9fa;
            color: #333;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
            padding: 10px 0;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        h3 {
            color: #2980b9;
            margin-top: 25px;
        }
        .toc {
            background: #ecf0f1;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .toc ul {
            list-style-type: none;
            padding-left: 0;
        }
        .toc li {
            margin: 8px 0;
        }
        .toc a {
            text-decoration: none;
            color: #2980b9;
            font-weight: 500;
        }
        .toc a:hover {
            color: #3498db;
        }
        .key-term {
            font-weight: bold;
            color: #e74c3c;
            background: #fdf2f2;
            padding: 2px 6px;
            border-radius: 4px;
        }
        .professor-note {
            background: #e8f5e8;
            border-left: 4px solid #27ae60;
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 8px 8px 0;
        }
        .professor-note::before {
            content: "üë®‚Äçüè´ Professor mentioned in class: ";
            font-weight: bold;
            color: #27ae60;
        }
        .hinglish-summary {
            background: linear-gradient(135deg, #fff5cd 0%, #ffe0b3 100%);
            border: 2px solid #ffa500;
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
            font-style: italic;
        }
        .hinglish-summary::before {
            content: "üéØ Hinglish Summary: ";
            font-weight: bold;
            color: #e67e22;
            font-style: normal;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #3498db;
            color: white;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .practice-questions {
            background: #f0f8ff;
            border: 2px solid #4169e1;
            border-radius: 10px;
            padding: 20px;
            margin: 25px 0;
        }
        .practice-questions h4 {
            color: #4169e1;
            margin-top: 0;
        }
        .key-takeaways {
            background: #f0fff0;
            border: 2px solid #32cd32;
            border-radius: 10px;
            padding: 20px;
            margin: 25px 0;
        }
        .key-takeaways h4 {
            color: #228b22;
            margin-top: 0;
        }
        .diagram-placeholder {
            background: #f5f5f5;
            border: 2px dashed #999;
            text-align: center;
            padding: 30px;
            margin: 20px 0;
            border-radius: 8px;
            font-style: italic;
            color: #666;
        }
        .formula-box {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            margin: 15px 0;
            text-align: center;
        }
        .instructor-info {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            text-align: center;
        }
        .mind-map {
            background: #f9f9f9;
            border: 2px solid #666;
            border-radius: 15px;
            padding: 30px;
            margin: 30px 0;
            text-align: center;
        }
        .mind-map-node {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 10px 15px;
            margin: 5px;
            border-radius: 20px;
            font-size: 14px;
        }
        .mind-map-subnode {
            display: inline-block;
            background: #95a5a6;
            color: white;
            padding: 5px 10px;
            margin: 3px;
            border-radius: 15px;
            font-size: 12px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="instructor-info">
            <h1>Foundations of Statistics & Probability</h1>
            <p><strong>Week 3 Lectures  note</strong></p>
            
        </div>

        <div class="toc">
            <h2>üìã Table of Contents</h2>
            <ul>
                <li><a href="#recap">1. Recap of Previous Topics</a></li>
                <li><a href="#chebyshev">2. Chebyshev's Inequality</a></li>
                <li><a href="#normal-dist">3. Normal Distribution</a></li>
                <li><a href="#clt">4. Central Limit Theorem</a></li>
                <li><a href="#paired-data">5. Paired Datasets</a></li>
                <li><a href="#scatter-plots">6. Scatter Plots and Correlation</a></li>
                <li><a href="#correlation-causation">7. Correlation vs Causation</a></li>
                <li><a href="#mind-map">8. Mind Map</a></li>
            </ul>
        </div>

        <section id="recap">
            <h2>1. Recap of Previous Topics</h2>
            
            <h3>What We've Covered So Far</h3>
            <ul>
                <li><span class="key-term">Data organization and visualization</span></li>
                <li><span class="key-term">Descriptive statistics</span> - introduction and fundamentals</li>
                <li><span class="key-term">Measures of central tendency</span> - mean, median, and mode</li>
                <li><span class="key-term">Measures of dispersion</span> - variance and standard deviation</li>
                <li><span class="key-term">Population vs Sample variance</span></li>
            </ul>

            <div class="professor-note">
                Standard deviation (œÉ) has the same units as the original data, while variance (œÉ¬≤) has squared units. This is why we commonly use standard deviation to express deviation from the mean, as it's more interpretable. For example, if variance is 25, then standard deviation is ¬±5.
            </div>

            <div class="hinglish-summary">
                Ab tak humne data ko kaise organize karna hai aur basic statistics ke concepts dekhe hain. Mean, median, mode jaise central tendency measures aur variance, standard deviation jaise dispersion measures samjhe hain. Yeh sab foundation concepts hain jo aage ke topics ke liye zaroori hain.
            </div>

            <div class="key-takeaways">
                <h4>üîë Key Takeaways</h4>
                <ul>
                    <li>Standard deviation (œÉ) is more interpretable than variance (œÉ¬≤)</li>
                    <li>Most values in a dataset typically fall within Œº ¬± œÉ range</li>
                    <li>Population variance uses N, sample variance uses N-1</li>
                </ul>
            </div>
        </section>

        <section id="chebyshev">
            <h2>2. Chebyshev's Inequality</h2>

            <h3>Definition and Importance</h3>
            <p><span class="key-term">Chebyshev's Inequality</span> is a fundamental theorem in probability that provides a bound on how much of the data deviates from the mean.</p>

            <div class="formula-box">
                <h4>Chebyshev's Inequality Formula</h4>

                $$P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}$$
                <p>Where:</p>
                <ul style="text-align: left; display: inline-block;">
                    <li>X = random variable</li>
                    <li>Œº = mean of the distribution</li>
                    <li>œÉ = standard deviation</li>
                    <li>k = number of standard deviations from mean</li>
                </ul>
            </div>

            <h3>Key Properties</h3>
            <table>
                <thead>
                    <tr>
                        <th>Property</th>
                        <th>Description</th>
                        <th>Advantage</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="key-term">Distribution-free</span></td>
                        <td>Does not assume normality</td>
                        <td>Applicable to any dataset</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Worst-case bound</span></td>
                        <td>Provides upper limit</td>
                        <td>Guarantees safety thresholds</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Practical utility</span></td>
                        <td>Used in real applications</td>
                        <td>Anomaly detection, AI evaluation</td>
                    </tr>
                </tbody>
            </table>

            <h3>Real-World Example 1: AI Fraud Detection System</h3>
            <p><strong>Scenario:</strong> An e-commerce company tracks daily transactions</p>
            <ul>
                <li>Mean transaction value (Œº) = $200</li>
                <li>Standard deviation (œÉ) = $50</li>
                <li>Question: What's the probability of fraudulent transactions (defined as 3œÉ away from mean)?</li>
            </ul>

            <div class="professor-note">
                Fraudulent transactions typically have extreme values - either very high ($10,000) or very low ($1). We can define these as transactions that deviate by 3 standard deviations from the mean.
            </div>

            <p><strong>Solution using Chebyshev's Inequality:</strong></p>
            <p>For k = 3:</p>

            $$P(|X - 200| \geq 3 \times 50) \leq \frac{1}{3^2} = \frac{1}{9} = 0.111 = 11.11\%$$

            <p><strong>Interpretation:</strong> At most 11.11% of transactions will be below $50 or above $350.</p>

            <h3>Real-World Example 2: AI-Powered Delivery System</h3>
            <p><strong>Scenario:</strong> Food delivery app tracking delivery times</p>
            <ul>
                <li>Mean delivery time (Œº) = 30 minutes</li>
                <li>Standard deviation (œÉ) = 5 minutes</li>
                <li>Company guarantee: deliveries within 20-40 minutes</li>
            </ul>

            <div class="diagram-placeholder">
                [Insert diagram: Delivery time distribution showing mean=30, œÉ=5, with 20-40 minute range marked]
            </div>

            <p><strong>Analysis:</strong></p>
            <ul>
                <li>Range 20-40 minutes = Œº ¬± 2œÉ (30 ¬± 10)</li>
                <li>For k = 2: Maximum proportion outside range = 1/k¬≤ = 1/4 = 25%</li>
                <li><strong>Result:</strong> At most 25% of deliveries might be outside 20-40 minutes</li>
                <li><strong>Company assurance:</strong> At least 75% deliveries will be within promised range</li>
            </ul>

            <p><strong>Additional scenario:</strong> "Very late" deliveries (>45 minutes = Œº + 3œÉ)</p>
            <p>For k = 3: At most 11.11% of deliveries will take more than 45 minutes</p>

            <div class="hinglish-summary">
                Chebyshev's inequality bahut powerful tool hai jo kisi bhi type ke data ke liye kaam karta hai. Yeh humein batata hai ki data points mean se kitna maximum deviate kar sakte hain. Real-world mein fraud detection aur delivery systems mein risk assessment ke liye use hota hai. Formula simple hai - k standard deviations ke liye maximum probability 1/k¬≤ hoti hai.
            </div>

            <div class="practice-questions">
                <h4>üéØ Practice Questions</h4>
                <ol>
                    <li><strong>Question:</strong> A dataset has mean = 100 and standard deviation = 15. Using Chebyshev's inequality, find the maximum proportion of values outside the range 70-130.
                        <br><strong>Answer:</strong> Range = Œº ¬± 2œÉ, so k=2. Maximum proportion = 1/4 = 25%</li>
                    
                    <li><strong>Question:</strong> For the same dataset, what's the minimum percentage of values within 3 standard deviations?
                        <br><strong>Answer:</strong> For k=3, maximum outside = 1/9 ‚âà 11.11%, so minimum inside = 88.89%</li>
                </ol>
            </div>

            <div class="key-takeaways">
                <h4>üîë Key Takeaways</h4>
                <ul>
                    <li>Chebyshev's inequality works for ANY distribution</li>
                    <li>Provides worst-case (upper bound) estimates</li>
                    <li>Formula: P(|X-Œº| ‚â• kœÉ) ‚â§ 1/k¬≤</li>
                    <li>Widely used in anomaly detection and risk assessment</li>
                </ul>
            </div>
        </section>

        <section id="normal-dist">
            <h2>3. Normal Distribution</h2>

            <h3>Definition and Characteristics</h3>
            <p>The <span class="key-term">normal distribution</span> describes how data points in a dataset tend to cluster around a central value, with most data points falling close to the mean and fewer occurring as you move further away.</p>

            <div class="diagram-placeholder">
                [Insert diagram: Bell-shaped curve showing normal distribution with peak at mean]
            </div>

            <h3>Key Properties of Normal Distribution</h3>
            <table>
                <thead>
                    <tr>
                        <th>Property</th>
                        <th>Description</th>
                        <th>Implication</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="key-term">Symmetry</span></td>
                        <td>Evenly distributed around mean</td>
                        <td>Mean = Median = Mode</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Bell-shaped curve</span></td>
                        <td>Characteristic shape</td>
                        <td>Also called Gaussian distribution</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Predictable range</span></td>
                        <td>68-95-99.7 rule</td>
                        <td>Most data within 3œÉ</td>
                    </tr>
                </tbody>
            </table>

            <h3>The 68-95-99.7 Rule (Empirical Rule)</h3>
            <div class="formula-box">
                <h4>For Normal Distribution:</h4>
                <ul style="text-align: left; display: inline-block;">
                    <li><strong>68%</strong> of data falls within <strong>1œÉ</strong> of the mean (Œº ¬± œÉ)</li>
                    <li><strong>95%</strong> of data falls within <strong>2œÉ</strong> of the mean (Œº ¬± 2œÉ)</li>
                    <li><strong>99.7%</strong> of data falls within <strong>3œÉ</strong> of the mean (Œº ¬± 3œÉ)</li>
                </ul>
            </div>

            <div class="professor-note">
                For example, if exam scores are normally distributed with mean = 70 and œÉ = 5, then approximately 68% of students scored between 65-75, 95% scored between 60-80, and 99.7% scored between 55-85.
            </div>

            <h3>Non-Normal Distributions</h3>
            
            <h4>Skewed Distributions</h4>
            <ul>
                <li><span class="key-term">Left-skewed (negatively skewed):</span> Long tail towards the left</li>
                <li><span class="key-term">Right-skewed (positively skewed):</span> Long tail towards the right</li>
            </ul>

            <div class="diagram-placeholder">
                [Insert diagram: Examples of left-skewed and right-skewed distributions]
            </div>

            <h4>Bimodal Distribution</h4>
            <p>A distribution with <span class="key-term">two distinct peaks</span> or local maxima, indicating two different subgroups in the data.</p>

            <div class="diagram-placeholder">
                [Insert diagram: Bimodal distribution with two peaks]
            </div>

            <h3>Real-World Examples of Normal Distribution</h3>
            <table>
                <thead>
                    <tr>
                        <th>Category</th>
                        <th>Examples</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="key-term">Natural Phenomena</span></td>
                        <td>Human height, weight, IQ scores, blood pressure</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Measurement Errors</span></td>
                        <td>Rounding errors, experimental errors</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Social & Economic</span></td>
                        <td>Exam scores, employee performance ratings</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Biological Processes</span></td>
                        <td>Birth weight, reaction times</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Industrial Processes</span></td>
                        <td>Product lifespans, manufacturing tolerances</td>
                    </tr>
                </tbody>
            </table>

            <h3>Normal Distribution vs Chebyshev's Inequality</h3>
            <div class="professor-note">
                While Chebyshev's inequality gives us worst-case bounds for ANY distribution, normal distribution gives us exact percentages. For example, Chebyshev says at most 25% of data is outside 2œÉ, but for normal distribution, exactly 5% is outside 2œÉ.
            </div>

            <table>
                <thead>
                    <tr>
                        <th>Standard Deviations</th>
                        <th>Chebyshev's Bound (Maximum Outside)</th>
                        <th>Normal Distribution (Exact Outside)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1œÉ</td>
                        <td>100% (no bound)</td>
                        <td>32%</td>
                    </tr>
                    <tr>
                        <td>2œÉ</td>
                        <td>25%</td>
                        <td>5%</td>
                    </tr>
                    <tr>
                        <td>3œÉ</td>
                        <td>11.11%</td>
                        <td>0.3%</td>
                    </tr>
                </tbody>
            </table>

            <div class="hinglish-summary">
                Normal distribution ek bell-shaped curve hai jo nature mein bahut commonly milta hai. Iska main advantage yeh hai ki hum exactly predict kar sakte hain ki kitna data kahan hoga. 68-95-99.7 rule yaad rakhiye - yeh bahut useful hai. Chebyshev se compare karne par, normal distribution zyada accurate predictions deta hai.
            </div>

            <div class="practice-questions">
                <h4>üéØ Practice Questions</h4>
                <ol>
                    <li><strong>Question:</strong> Heights of students are normally distributed with mean = 170 cm and œÉ = 8 cm. What percentage of students have height between 162-178 cm?
                        <br><strong>Answer:</strong> This is Œº ¬± œÉ range, so 68% of students</li>
                    
                    <li><strong>Question:</strong> For the same data, what percentage have height greater than 186 cm?
                        <br><strong>Answer:</strong> 186 = Œº + 2œÉ, so 2.5% (half of the 5% outside 2œÉ)</li>
                </ol>
            </div>

            <div class="key-takeaways">
                <h4>üîë Key Takeaways</h4>
                <ul>
                    <li>Normal distribution is symmetric and bell-shaped</li>
                    <li>Mean = Median = Mode for normal distribution</li>
                    <li>68-95-99.7 rule provides exact percentages</li>
                    <li>Common in natural and social phenomena</li>
                    <li>More precise than Chebyshev's inequality for normal data</li>
                </ul>
            </div>
        </section>

        <section id="clt">
            <h2>4. Central Limit Theorem</h2>

            <h3>Definition</h3>
            <p>The <span class="key-term">Central Limit Theorem</span> states that given a sufficiently large sample size, the distribution of the sample mean (or sum) of a random variable will approach a normal distribution, regardless of the original distribution of the population.</p>

            <div class="formula-box">
                <h4>Central Limit Theorem</h4>
                <p>As sample size n ‚Üí ‚àû, the sampling distribution of the mean approaches normal distribution:</p>

                $$\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$$
                <p>Where $\bar{X}$ is the sample mean</p>
            </div>

            <h3>Key Implications</h3>
            <ul>
                <li><span class="key-term">Universal applicability:</span> Works regardless of original distribution shape</li>
                <li><span class="key-term">Large sample requirement:</span> Generally n ‚â• 30 is considered sufficient</li>
                <li><span class="key-term">Practical importance:</span> Explains why normal distribution is so common in nature</li>
            </ul>

            <div class="professor-note">
                This theorem explains why many real-world phenomena follow normal distribution. When multiple independent factors contribute to a process (like height being influenced by genetics, nutrition, environment), the aggregate effect tends to be normally distributed.
            </div>

            <div class="diagram-placeholder">
                [Insert diagram: Illustration showing how different distributions converge to normal as sample size increases]
            </div>

            <h3>Real-World Applications</h3>
            <table>
                <thead>
                    <tr>
                        <th>Field</th>
                        <th>Application</th>
                        <th>Why CLT Applies</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Manufacturing</td>
                        <td>Quality control</td>
                        <td>Multiple factors affect product quality</td>
                    </tr>
                    <tr>
                        <td>Biology</td>
                        <td>Height, weight measurements</td>
                        <td>Multiple genes and environmental factors</td>
                    </tr>
                    <tr>
                        <td>Finance</td>
                        <td>Stock price movements</td>
                        <td>Many market factors influence prices</td>
                    </tr>
                    <tr>
                        <td>Psychology</td>
                        <td>Test scores, reaction times</td>
                        <td>Multiple cognitive and environmental factors</td>
                    </tr>
                </tbody>
            </table>

            <div class="hinglish-summary">
                Central Limit Theorem ek bahut important concept hai jo explain karta hai ki normal distribution itni common kyun hai nature mein. Jab bhi multiple factors milke koi outcome produce karte hain, toh result normal distribution follow karta hai, chahe original distribution kuchh bhi ho. Yeh theorem statistics ki foundation hai.
            </div>

            <div class="key-takeaways">
                <h4>üîë Key Takeaways</h4>
                <ul>
                    <li>Sample means approach normal distribution as n increases</li>
                    <li>Works regardless of original population distribution</li>
                    <li>Explains prevalence of normal distribution in nature</li>
                    <li>Foundation for many statistical inference methods</li>
                </ul>
            </div>
        </section>

        <section id="paired-data">
            <h2>5. Paired Datasets</h2>

            <h3>Definition</h3>
            <p>A <span class="key-term">paired dataset</span> consists of two related variables collected for each individual or observation. Instead of measuring just one characteristic, we measure two characteristics for the same subjects.</p>

            <h3>Examples of Paired Data</h3>
            <table>
                <thead>
                    <tr>
                        <th>Context</th>
                        <th>Variable 1</th>
                        <th>Variable 2</th>
                        <th>Purpose</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Health Study</td>
                        <td>Caffeine consumption</td>
                        <td>Heart rate</td>
                        <td>Study relationship between caffeine and heart rate</td>
                    </tr>
                    <tr>
                        <td>Student Behavior</td>
                        <td>Social media hours</td>
                        <td>Sleep duration</td>
                        <td>Analyze impact of screen time on sleep</td>
                    </tr>
                    <tr>
                        <td>Academic Performance</td>
                        <td>Study hours</td>
                        <td>Exam scores</td>
                        <td>Examine study time effectiveness</td>
                    </tr>
                </tbody>
            </table>

            <h3>Sample Dataset: Social Media vs Sleep</h3>
            <table>
                <thead>
                    <tr>
                        <th>Friend</th>
                        <th>Social Media Hours</th>
                        <th>Sleep Duration (hours)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>1</td><td>2</td><td>8</td></tr>
                    <tr><td>2</td><td>4</td><td>7</td></tr>
                    <tr><td>3</td><td>1</td><td>9</td></tr>
                    <tr><td>4</td><td>6</td><td>6</td></tr>
                    <tr><td>5</td><td>8</td><td>5</td></tr>
                    <tr><td>6</td><td>5</td><td>6.5</td></tr>
                    <tr><td>7</td><td>7</td><td>5.5</td></tr>
                    <tr><td>8</td><td>3</td><td>8</td></tr>
                    <tr><td>9</td><td>9</td><td>4.5</td></tr>
                    <tr><td>10</td><td>10</td><td>4</td></tr>
                </tbody>
            </table>

            <h3>Sample Dataset: Study Time vs Exam Scores</h3>
            <table>
                <thead>
                    <tr>
                        <th>Student</th>
                        <th>Study Time (hours)</th>
                        <th>Exam Score</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>1</td><td>8.1</td><td>88.1</td></tr>
                    <tr><td>2</td><td>5.4</td><td>75.2</td></tr>
                    <tr><td>3</td><td>4.0</td><td>68.2</td></tr>
                    <tr><td>4</td><td>2.0</td><td>54.9</td></tr>
                    <tr><td>5</td><td>3.1</td><td>56.0</td></tr>
                    <tr><td>6</td><td>9.5</td><td>94.4</td></tr>
                    <tr><td>7</td><td>3.7</td><td>69.7</td></tr>
                    <tr><td>8</td><td>2.5</td><td>55.9</td></tr>
                    <tr><td>9</td><td>5.1</td><td>75.8</td></tr>
                    <tr><td>10</td><td>3.8</td><td>78.3</td></tr>
                </tbody>
            </table>

            <div class="professor-note">
                The key difference from single-variable datasets is that each observation (person, student, etc.) contributes TWO data points that are related to each other. This relationship is what we want to analyze and understand.
            </div>

            <div class="hinglish-summary">
                Paired datasets mein hum ek hi subject ke liye do variables measure karte hain. Jaise ek student ka study time aur uska exam score, ya phir social media time aur sleep duration. Yeh data humein relationships samjhane mein help karta hai between different factors.
            </div>

            <div class="key-takeaways">
                <h4>üîë Key Takeaways</h4>
                <ul>
                    <li>Paired data involves two variables per observation</li>
                    <li>Best visualized using scatter plots</li>
                    <li>Helps identify relationships between variables</li>
                    <li>Each data point represents one individual/observation</li>
                </ul>
            </div>
        </section>

        <section id="scatter-plots">
            <h2>6. Scatter Plots and Correlation</h2>

            <h3>Scatter Plots</h3>
            <p><span class="key-term">Scatter plots</span> are the best visual tool to represent paired datasets and identify patterns between two variables.</p>

            <h3>How to Create Scatter Plots</h3>
            <ol>
                <li>Place one variable on the horizontal (x) axis</li>
                <li>Place the other variable on the vertical (y) axis</li>
                <li>Plot each observation as a point with coordinates (x, y)</li>
                <li>Analyze the resulting pattern</li>
            </ol>

            <div class="diagram-placeholder">
                [Insert diagram: Example scatter plot showing social media hours vs sleep duration with negative correlation]
            </div>

            <h3>Types of Relationships</h3>

            <h4>1. Positive Relationship</h4>
            <ul>
                <li>As one variable increases, the other also increases</li>
                <li>Upward sloping pattern</li>
                <li><strong>Example:</strong> Study time vs exam scores</li>
            </ul>

            <div class="diagram-placeholder">
                [Insert diagram: Positive correlation scatter plot]
            </div>

            <h4>2. Negative Relationship</h4>
            <ul>
                <li>As one variable increases, the other decreases</li>
                <li>Downward sloping pattern</li>
                <li><strong>Example:</strong> Social media time vs sleep duration</li>
            </ul>

            <div class="diagram-placeholder">
                [Insert diagram: Negative correlation scatter plot]
            </div>

            <h4>3. No Relationship</h4>
            <ul>
                <li>No discernible pattern</li>
                <li>Points scattered randomly</li>
                <li><strong>Example:</strong> Shoe size vs grocery expenditure</li>
            </ul>

            <div class="diagram-placeholder">
                [Insert diagram: No correlation scatter plot with random distribution]
            </div>

            <h3>Correlation Strength</h3>
            <table>
                <thead>
                    <tr>
                        <th>Slope Characteristic</th>
                        <th>Correlation Strength</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="key-term">Steep slope</span></td>
                        <td>Strong correlation</td>
                        <td>Large change in Y for small change in X</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Moderate slope</span></td>
                        <td>Moderate correlation</td>
                        <td>Moderate change in Y for change in X</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Flat slope</span></td>
                        <td>Weak correlation</td>
                        <td>Small change in Y despite change in X</td>
                    </tr>
                </tbody>
            </table>

            <h3>Sample Correlation Coefficient (r)</h3>
            <p>The <span class="key-term">sample correlation coefficient</span> quantifies the strength and direction of linear relationship between two variables.</p>

            <div class="formula-box">
                <h4>Correlation Coefficient Formula</h4>

                $$r = \frac{\sum_{i=1}^{n}(X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum_{i=1}^{n}(X_i - \bar{X})^2 \sum_{i=1}^{n}(Y_i - \bar{Y})^2}}$$
                <p>Where:</p>
                <ul style="text-align: left; display: inline-block;">
                    <li>$X_i, Y_i$ = individual data points</li>
                    <li>$\bar{X}, \bar{Y}$ = sample means</li>
                    <li>r ranges from -1 to +1</li>
                </ul>
            </div>

            <h3>Interpreting Correlation Coefficient</h3>
            <table>
                <thead>
                    <tr>
                        <th>r Value</th>
                        <th>Strength</th>
                        <th>Direction</th>
                        <th>Interpretation</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>r = +1</td>
                        <td>Perfect</td>
                        <td>Positive</td>
                        <td>Perfect positive linear relationship</td>
                    </tr>
                    <tr>
                        <td>r = +0.8 to +0.9</td>
                        <td>Strong</td>
                        <td>Positive</td>
                        <td>Strong positive correlation</td>
                    </tr>
                    <tr>
                        <td>r = +0.3 to +0.7</td>
                        <td>Moderate</td>
                        <td>Positive</td>
                        <td>Moderate positive correlation</td>
                    </tr>
                    <tr>
                        <td>r = 0</td>
                        <td>None</td>
                        <td>-</td>
                        <td>No linear relationship</td>
                    </tr>
                    <tr>
                        <td>r = -0.3 to -0.7</td>
                        <td>Moderate</td>
                        <td>Negative</td>
                        <td>Moderate negative correlation</td>
                    </tr>
                    <tr>
                        <td>r = -0.8 to -0.9</td>
                        <td>Strong</td>
                        <td>Negative</td>
                        <td>Strong negative correlation</td>
                    </tr>
                    <tr>
                        <td>r = -1</td>
                        <td>Perfect</td>
                        <td>Negative</td>
                        <td>Perfect negative linear relationship</td>
                    </tr>
                </tbody>
            </table>

            <h3>Real-World Examples with Correlation Values</h3>

            <div class="professor-note">
                Using Google Sheets CORREL function: =CORREL(range1, range2). For the study time vs exam scores example, we got r = 0.93, indicating a strong positive correlation.
            </div>

            <table>
                <thead>
                    <tr>
                        <th>Dataset</th>
                        <th>Correlation (r)</th>
                        <th>Interpretation</th>
                        <th>Real-world Explanation</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Temperature vs Hot Beverage Sales</td>
                        <td>Strong negative (r ‚âà -0.8)</td>
                        <td>Strong negative correlation</td>
                        <td>People buy fewer hot drinks when it's hot outside</td>
                    </tr>
                    <tr>
                        <td>Screen Time vs Sleep Duration</td>
                        <td>Moderate negative (r ‚âà -0.7)</td>
                        <td>Moderate negative correlation</td>
                        <td>More screen time tends to reduce sleep duration</td>
                    </tr>
                    <tr>
                        <td>Study Hours vs Exam Scores</td>
                        <td>Strong positive (r ‚âà 0.93)</td>
                        <td>Strong positive correlation</td>
                        <td>More study time generally leads to better scores</td>
                    </tr>
                    <tr>
                        <td>Steps vs Calories Consumed</td>
                        <td>Weak positive (r ‚âà 0.2)</td>
                        <td>Weak positive correlation</td>
                        <td>More walking might increase appetite slightly</td>
                    </tr>
                    <tr>
                        <td>Shoe Size vs Grocery Spending</td>
                        <td>Nearly zero (r ‚âà 0.01)</td>
                        <td>No correlation</td>
                        <td>No logical relationship between these variables</td>
                    </tr>
                </tbody>
            </table>

            <h3>Understanding Covariance</h3>
            <p>The numerator in the correlation formula represents <span class="key-term">covariance</span> - how X and Y vary together:</p>
            <ul>
                <li><strong>Positive covariance:</strong> Both variables increase/decrease together</li>
                <li><strong>Negative covariance:</strong> One increases while other decreases</li>
                <li><strong>Zero covariance:</strong> No relationship between variables</li>
            </ul>

            <div class="professor-note">
                The denominator in the correlation formula standardizes the covariance by the variability in each variable individually. This ensures r is dimensionless and falls between -1 and +1, making it easy to interpret regardless of the units of measurement.
            </div>

            <div class="hinglish-summary">
                Scatter plots paired data ko visualize karne ka best way hai. Correlation coefficient (r) humein exact measurement deta hai relationship ka strength aur direction ka. Google Sheets mein CORREL function use kar sakte hain. Remember: steep slope = strong correlation, flat slope = weak correlation. Positive/negative direction slope se pata chal jata hai.
            </div>

            <div class="practice-questions">
                <h4>üéØ Practice Questions</h4>
                <ol>
                    <li><strong>Question:</strong> A scatter plot shows points forming a steep downward trend. What can you conclude about the correlation?
                        <br><strong>Answer:</strong> Strong negative correlation (r close to -1)</li>
                    
                    <li><strong>Question:</strong> If r = 0.85 for height vs weight data, what does this indicate?
                        <br><strong>Answer:</strong> Strong positive correlation - taller people tend to weigh more</li>
                    
                    <li><strong>Question:</strong> Calculate the correlation interpretation: r = -0.45
                        <br><strong>Answer:</strong> Moderate negative correlation</li>
                </ol>
            </div>

            <div class="key-takeaways">
                <h4>üîë Key Takeaways</h4>
                <ul>
                    <li>Scatter plots visualize relationships in paired data</li>
                    <li>Correlation coefficient (r) quantifies relationship strength</li>
                    <li>r ranges from -1 (perfect negative) to +1 (perfect positive)</li>
                    <li>Steep slopes indicate strong correlations</li>
                    <li>Google Sheets function: =CORREL(range1, range2)</li>
                </ul>
            </div>
        </section>

        <section id="correlation-causation">
            <h2>7. Correlation vs Causation</h2>

            <h3>The Critical Distinction</h3>
            <p><span class="key-term">Correlation does NOT imply causation</span> - This is one of the most important principles in statistics and data analysis.</p>

            <div class="formula-box">
                <h4>Key Principle</h4>
                <p style="font-size: 18px; color: #e74c3c;">
                    <strong>Correlation ‚â† Causation</strong>
                </p>
                <p>Just because two variables are correlated doesn't mean one causes the other</p>
            </div>

            <h3>Why Correlation ‚â† Causation</h3>
            <table>
                <thead>
                    <tr>
                        <th>Factor</th>
                        <th>Explanation</th>
                        <th>Example</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="key-term">Hidden variables</span></td>
                        <td>Third factor influences both variables</td>
                        <td>Hot weather causes both ice cream sales and drowning incidents</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Reverse causation</span></td>
                        <td>Effect might cause the "cause"</td>
                        <td>Do high scores cause more study time or vice versa?</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Coincidence</span></td>
                        <td>Random relationship</td>
                        <td>Shoe size and grocery spending correlation</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Multiple factors</span></td>
                        <td>Many variables influence outcome</td>
                        <td>Exam scores depend on study quality, sleep, stress, etc.</td>
                    </tr>
                </tbody>
            </table>

            <h3>Classic Examples</h3>

            <h4>Example 1: Ice Cream Sales vs Drowning Incidents</h4>
            <ul>
                <li><strong>Observation:</strong> Strong positive correlation between ice cream sales and drowning incidents</li>
                <li><strong>Wrong conclusion:</strong> Eating ice cream causes drowning</li>
                <li><strong>Actual explanation:</strong> Hot weather causes both:
                    <ul>
                        <li>People buy more ice cream when it's hot</li>
                        <li>People swim more when it's hot ‚Üí more swimming incidents</li>
                    </ul>
                </li>
                <li><strong>Hidden variable:</strong> Temperature/Hot weather</li>
            </ul>

            <h4>Example 2: Study Hours vs Exam Scores</h4>
            <ul>
                <li><strong>Observation:</strong> r = 0.93 (strong positive correlation)</li>
                <li><strong>Tempting conclusion:</strong> More study hours directly cause higher scores</li>
                <li><strong>Reality check:</strong> Other factors matter:
                    <ul>
                        <li>Quality of study time</li>
                        <li>Student's mental state during exam</li>
                        <li>Prior knowledge and preparation</li>
                        <li>Test-taking skills</li>
                        <li>Sleep and health conditions</li>
                    </ul>
                </li>
            </ul>

            <div class="professor-note">
                We all know that simply sitting with books for long hours doesn't guarantee good scores. The quality of study, understanding concepts, and many other factors play crucial roles. Correlation only shows there's a relationship, not that one directly causes the other.
            </div>

            <h3>How to Establish Causation</h3>
            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>Description</th>
                        <th>Strength</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="key-term">Controlled experiments</span></td>
                        <td>Control all variables except the one being tested</td>
                        <td>Gold standard for causation</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Longitudinal studies</span></td>
                        <td>Track changes over time</td>
                        <td>Good for identifying temporal relationships</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Multiple evidence sources</span></td>
                        <td>Combine different types of studies</td>
                        <td>Builds stronger case for causation</td>
                    </tr>
                    <tr>
                        <td><span class="key-term">Randomized trials</span></td>
                        <td>Randomly assign treatments</td>
                        <td>Eliminates selection bias</td>
                    </tr>
                </tbody>
            </table>

            <h3>Guidelines for Interpreting Correlations</h3>
            <ol>
                <li><strong>Look for hidden variables:</strong> What else might influence both variables?</li>
                <li><strong>Consider reverse causation:</strong> Could the "effect" cause the "cause"?</li>
                <li><strong>Think about confounding factors:</strong> What other variables weren't measured?</li>
                <li><strong>Use domain knowledge:</strong> Does the relationship make logical sense?</li>
                <li><strong>Seek additional evidence:</strong> Look for experimental or longitudinal data</li>
            </ol>

            <h3>Practical Applications in AI and Data Science</h3>

            <div class="professor-note">
                In AI and machine learning, we often use correlations to make predictions. However, we must be careful not to assume causation. For example, an AI model might find that people who buy certain products also buy others (correlation), but this doesn't mean one purchase causes the other.
            </div>

            <table>
                <thead>
                    <tr>
                        <th>AI Application</th>
                        <th>Correlation Used</th>
                        <th>Causation Caution</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Recommendation systems</td>
                        <td>Purchase patterns</td>
                        <td>Correlation used for prediction, not causation</td>
                    </tr>
                    <tr>
                        <td>Medical diagnosis</td>
                        <td>Symptom correlations</td>
                        <td>Must verify causal relationships through medical research</td>
                    </tr>
                    <tr>
                        <td>Marketing analytics</td>
                        <td>Campaign performance</td>
                        <td>A/B testing needed to establish causal effects</td>
                    </tr>
                </tbody>
            </table>

            <div class="hinglish-summary">
                Correlation aur causation mein bahut fark hai! Sirf isliye ki do cheezein related hain, matlab yeh nahi ki ek dusre ko cause kar rahi hai. Hidden factors ho sakte hain, ya phir reverse causation ho sakta hai. AI aur data science mein hum correlation use karte hain predictions ke liye, lekin causation establish karne ke liye proper experiments chahiye. Always think critically!
            </div>

            <div class="practice-questions">
                <h4>üéØ Practice Questions</h4>
                <ol>
                    <li><strong>Question:</strong> Strong positive correlation found between coffee consumption and productivity at work. Can we conclude coffee causes higher productivity?
                        <br><strong>Answer:</strong> No. Possible hidden factors: motivated people might drink more coffee AND be more productive; early morning workers might need coffee and also be more productive during peak hours.</li>
                    
                    <li><strong>Question:</strong> Data shows negative correlation between TV watching and academic performance. What should we be careful about?
                        <br><strong>Answer:</strong> Don't assume TV causes poor performance. Consider: students with less academic interest might watch more TV; family circumstances might affect both TV time and study support.</li>
                </ol>
            </div>

            <div class="key-takeaways">
                <h4>üîë Key Takeaways</h4>
                <ul>
                    <li>Correlation ‚â† Causation - fundamental principle in statistics</li>
                    <li>Hidden variables often explain correlations</li>
                    <li>Controlled experiments needed to establish causation</li>
                    <li>Always think critically about relationships in data</li>
                    <li>Use correlation for prediction, not causal inference</li>
                </ul>
            </div>
        </section>

        <section id="mind-map">
            <h2>8. Comprehensive Mind Map</h2>
            
            <div class="mind-map">
                <h3>Module 02: Measures of Central Tendency (Continued)</h3>
                
                <div style="margin: 20px 0;">
                    <div class="mind-map-node">Chebyshev's Inequality</div>
                    <div class="mind-map-subnode">Distribution-free</div>
                    <div class="mind-map-subnode">P(|X-Œº| ‚â• kœÉ) ‚â§ 1/k¬≤</div>
                    <div class="mind-map-subnode">Fraud detection</div>
                    <div class="mind-map-subnode">Delivery systems</div>
                </div>

                <div style="margin: 20px 0;">
                    <div class="mind-map-node">Normal Distribution</div>
                    <div class="mind-map-subnode">Bell-shaped curve</div>
                    <div class="mind-map-subnode">68-95-99.7 rule</div>
                    <div class="mind-map-subnode">Symmetric</div>
                    <div class="mind-map-subnode">Mean=Median=Mode</div>
                </div>

                <div style="margin: 20px 0;">
                    <div class="mind-map-node">Central Limit Theorem</div>
                    <div class="mind-map-subnode">Large sample ‚Üí Normal</div>
                    <div class="mind-map-subnode">Any distribution</div>
                    <div class="mind-map-subnode">Explains prevalence</div>
                </div>

                <div style="margin: 20px 0;">
                    <div class="mind-map-node">Paired Datasets</div>
                    <div class="mind-map-subnode">Two variables per observation</div>
                    <div class="mind-map-subnode">Scatter plots</div>
                    <div class="mind-map-subnode">Relationship analysis</div>
                </div>

                <div style="margin: 20px 0;">
                    <div class="mind-map-node">Correlation</div>
                    <div class="mind-map-subnode">r = -1 to +1</div>
                    <div class="mind-map-subnode">Strength & Direction</div>
                    <div class="mind-map-subnode">CORREL function</div>
                    <div class="mind-map-subnode">‚â† Causation</div>
                </div>

                <div style="margin: 20px 0;">
                    <div class="mind-map-node">Applications</div>
                    <div class="mind-map-subnode">AI systems</div>
                    <div class="mind-map-subnode">Quality control</div>
                    <div class="mind-map-subnode">Risk assessment</div>
                    <div class="mind-map-subnode">Data analysis</div>
                </div>
            </div>
        </section>

        <div style="text-align: center; margin-top: 50px; padding: 20px; background: #f8f9fa; border-radius: 10px;">
            <h3>I created this knowledge during my first semester of BSc in Applied AI and Data Science. </h3>
        <h3>~ Armaan Kachhawa</h3>
    </div>
    </div>
</body>
</html>